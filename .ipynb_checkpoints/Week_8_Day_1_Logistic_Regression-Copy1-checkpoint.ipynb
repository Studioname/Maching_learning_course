{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4807992e",
   "metadata": {},
   "source": [
    "# Week 8 - Logistic Regression\n",
    "\n",
    "## Python Packages for Logistic Regression\n",
    "\n",
    "For Logistic regression, we need **NumPy** and **scikit-learn**. \n",
    "\n",
    "https://numpy.org/doc/\n",
    "\n",
    "https://scikit-learn.org/stable/\n",
    "\n",
    "Numpy handles the numerical and scientific computing and is highly performant on single and multi-dimensional arrays. Scikit-learn allows us to:\n",
    "\n",
    "- Preprocess data\n",
    "- Reduce the dimensionality of problems\n",
    "- Validate models\n",
    "- Select the most appropriate model\n",
    "- Solve regression and classification problems\n",
    "- Implement cluster analysis\n",
    "\n",
    "If we need functionality that scikit-learn can't provide then we use **StatsModels**. \n",
    "\n",
    "https://www.statsmodels.org/stable/index.html\n",
    "\n",
    "Finally, we'll use **MatPlotLib** to visualise the resluts of our classification. \n",
    "\n",
    "### Logistic Regression in Python with Scikit-Learn, Example 1\n",
    "\n",
    "Our first example relates to a **single-variate binary classification problem**. This is the most straightforward type of classification problem. \n",
    "\n",
    "#### Step 1. Import Packages, Functions and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4717516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d11a2bd",
   "metadata": {},
   "source": [
    "#### Step 2. Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2c7a50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we'll use lists of numbers as simple datasets\n",
    "\n",
    "x = np.arange(10).reshape(-1, 1)\n",
    "y = np.array([0,0,0,0,1,1,1,1,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e11dfde",
   "metadata": {},
   "source": [
    "**x array has to be 2-dimensional**. It should have **one column for each input, and the number of rows should  be equal to the number of observations**. To **make x 2-dimensional**, we **apply .reshape() with the arguments -1 [to get as many rows as needed] and 1 to get one column**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05375cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [6],\n",
       "        [7],\n",
       "        [8],\n",
       "        [9]]),\n",
       " array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb0ffc7",
   "metadata": {},
   "source": [
    "**x has two dimensions:**\n",
    "\n",
    "1. **One column** for a single input\n",
    "2. **Ten rows**, each corresponding to one observation\n",
    "\n",
    "**y is 1-dimensional** with ten items. Again, each item corresponds to one observation. It contains only zeroes and ones since this is a binary classification problem.\n",
    "\n",
    "#### Step 3. Create a Model and Train it\n",
    "\n",
    "When we have prepared the input and output, we can create and define our classification model. It contains only zeroes and ones because it is a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5260b72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607e459e",
   "metadata": {},
   "source": [
    "**LogisticRegression** has several **optional parameters**:\n",
    "\n",
    "- **penalty** is a **string ('l2' by default)** that decides **whether there is regularisation and which approach to use**. Other options are **'l1', 'elasticnet' and 'none'**. [L1, L2 etc]\n",
    "\n",
    "- **dual** is a **Boolean (False by default)** that decides **whether to use primal (False) or dual formulation (True)**.\n",
    "\n",
    "- **tol** is a **floating point number (1.0 by default)** that defines the **tolerance for stopping the procedure**.\n",
    "\n",
    "- **C** is a **floating point number (1.0 by default)** that defines the **relative strength of regularisation. Smaller values indicate stronger regularisation**.\n",
    "\n",
    "- **fit_intercept** is a **Boolean (True by default)** that decides **whether to calculate the intercept b0 (when True) or consider it equal to zero (when False)**.\n",
    "\n",
    "- **intercept_scaling is a **floating point number (1.0 by default)** that defines the **scaling of the intercept b0**.\n",
    "\n",
    "- **class_weight** is a **dictionary, 'balanced' or None (default)** that **defines the weights related to each class. When None, all classes have the weight 1.**\n",
    "\n",
    "- **random_state** is an **integer, an instance of numpy.RandomState, or None (default)** that defines **what pseudo-random number generator to use**.\n",
    "\n",
    "- **solver** is a **string ('liblinear' by default)** that decides **what solver to use for fitting the model. Other options are 'newton-cg', 'lbfgs', 'sag', and 'saga'.**\n",
    "\n",
    "- **max_iter** is an **integer (100 by default)** that defines the **maximum number of iterations by the solver during model fitting**.\n",
    "\n",
    "- **multi_class** is a **string ('ovr' by default)** that decides the approach for **handling multiple classes. Other options are 'multinomial' and 'auto')**.\n",
    "\n",
    "- **verbose** is a **non-negative integer (0 by default)** that defines the **verbosity for the 'liblinear' and 'lbfgs' solvers**.\n",
    "\n",
    "- **warm_start** is a **Boolean (False by default)** that decides **whether to reuse the previously obtained solution**.\n",
    "\n",
    "- **n_jobs** is an **integer or None (default)** that defines what the **number of parallel processes to use**. **None usually maeans to use one core, while -1 means to use all available ones.**\n",
    "\n",
    "- **l1_ratio** is a **floating point number between 0 and 1 or None (default)** which defines the **relative importance of the L1 part in the elastic-net regularisation**.\n",
    "\n",
    "**We should carefully match the solver and regularisation method for several reasons**:\n",
    "\n",
    "1. **'liblinear'** solver **doesn't work without regularisation**\n",
    "2. **'newton-cg', 'sag', 'saga' and 'lbfgs' don't support L1 regularisation**\n",
    "3. **'saga' is the only solver that supports elastic-net regularisation**\n",
    "\n",
    "**Once the model is created, we need to fit [or train] it. Model fitting is** the process of **determining the coefficients b0, b1...bn that correspond to the best value of the cost function.** You fit the model with **.fit()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28657e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd93889b",
   "metadata": {},
   "source": [
    "**.fit()** takes **x, y, and possibly observation-related weights**. Then it **fits the model** and **returns the model instance itself**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5401c49d",
   "metadata": {},
   "source": [
    "As seen before, we can chain the last two lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4252da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=0).fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12eaa93",
   "metadata": {},
   "source": [
    "We can **get the attributes** of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01c4a840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44c79434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.04608067])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f30039b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51491375]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02afab58",
   "metadata": {},
   "source": [
    "#### Step 4. Evaluate the Model\n",
    "\n",
    "We can **check our model's performance with .predict_proba()**, which **returns the matrix of probabilities that the predicted output is equal to 0 or 1**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d121124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74002157, 0.25997843],\n",
       "       [0.62975524, 0.37024476],\n",
       "       [0.5040632 , 0.4959368 ],\n",
       "       [0.37785549, 0.62214451],\n",
       "       [0.26628093, 0.73371907],\n",
       "       [0.17821501, 0.82178499],\n",
       "       [0.11472079, 0.88527921],\n",
       "       [0.07186982, 0.92813018],\n",
       "       [0.04422513, 0.95577487],\n",
       "       [0.02690569, 0.97309431]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24953886",
   "metadata": {},
   "source": [
    "In the matrix above, **each row corresponds to a single observation**. The **first column** is the **probability of the predicted output being 0, or 1-p(x)].** The **second column** is the **probability that the output is 1, or p(x)**.\n",
    "\n",
    "We can get the **acual predictions**, based on the probability matrix and the values of p(x) using **.predict():**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32dfc07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c286e901",
   "metadata": {},
   "source": [
    "This function returns the predicted output values as 1-Dimensional array. \n",
    "\n",
    "We can **obtain the accuracy** of our model using **.score()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e1da408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31eea76c",
   "metadata": {},
   "source": [
    "**.score()** takes the input and output as arguments and returns the ratio of the number of correct predictions to the number of observations.\n",
    "\n",
    "**Our score is 0.9**. This means that our model has an **accuracy of 90%**. So if our dataset consists of 10 items, then it **must have made 1 incorrect prediction**.\n",
    "\n",
    "We can get more information on the accuracy of a model with a **confusion matrix**. In the case of binary classification, a confusion matrix shows the numbers of the following:\n",
    "\n",
    "- **True negatives** in the **upper-left** position\n",
    "- **False negatives** in the **lower-left** position\n",
    "- **False positives** in the **upper-right** position\n",
    "- **True positives** in the **lower-right** position\n",
    "\n",
    "**To create the confusion matrix**, you can use **confusion_matrix() and provide the actual and predicted outputs as arguments:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba0d2c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 1],\n",
       "       [0, 6]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, model.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f271ed4a",
   "metadata": {},
   "source": [
    "Our matrix shows the following:\n",
    "\n",
    "- **3 True negative predictions**\n",
    "- **0 False negative predictions**\n",
    "- **1 False positive prediction** (wrong)\n",
    "- **6 True positive predictions**\n",
    "\n",
    "**It's often useful to visualise the confusion matrix.** We can do this with **.imshow() from Matplotlib**, which **accepts the confusion matrix as the argument**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fef7e3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y, model.predict(x))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0,1), ticklabels=(\"Predicted 0's\", \"Predicted 1's\"))\n",
    "ax.yaxis.set(ticks=(0,1), ticklabels=(\"Actual 0's\", \"Actual 1's\"))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca7c1b4",
   "metadata": {},
   "source": [
    "This is a **heatmap representing the confusion matrix**. \n",
    "\n",
    "In this figure, **different colours represent different numbers** and **similar colours represent similar numbers**. Heatmaps are a nice and convenient way to represent a matrix. \n",
    "\n",
    "We can get a more **comprehensive report** on the classification with **classification_report()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e2cf4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.93      0.88      0.89        10\n",
      "weighted avg       0.91      0.90      0.90        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y,model.predict(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1123893",
   "metadata": {},
   "source": [
    "**This function takes the actual and predicted outputs as arguments**. It **returns a report on the classification as a dictionary if you provide output_dict=True or a string otherwise**. \n",
    "\n",
    "Note: It's usually better to evaluate your model with the data you didn't use for training. That's how you avoid bias and detect overfitting.\n",
    "\n",
    "#### Improve the Model\n",
    "\n",
    "We can **improve the model** by **setting different parameters**. For example let's start with **regularisation strength C** and **set it to 10.00, instead of 1.00**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65abb18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', C=10.0, random_state=0).fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec72da6",
   "metadata": {},
   "source": [
    "Now we have **another model with different parameters**. It has a **different probability matrix** and a **different set of coefficients and predictions**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3fcb9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.51335372])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a14589e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.12066084]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f5a99e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97106534, 0.02893466],\n",
       "       [0.9162684 , 0.0837316 ],\n",
       "       [0.7810904 , 0.2189096 ],\n",
       "       [0.53777071, 0.46222929],\n",
       "       [0.27502212, 0.72497788],\n",
       "       [0.11007743, 0.88992257],\n",
       "       [0.03876835, 0.96123165],\n",
       "       [0.01298011, 0.98701989],\n",
       "       [0.0042697 , 0.9957303 ],\n",
       "       [0.00139621, 0.99860379]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f63b1e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb3f576",
   "metadata": {},
   "source": [
    "As we can see, **the absolute values of the intercept b0 and the coefficient b1 are larger.** This is because the **larger value of C means weaker regularisation**, or weaker penalisation related to high values of b0 and b1.\n",
    "\n",
    "Different values of b0 and b1 imply a change of the logit f(x), different values of the probabilities p(x), a different shape of the regression line, and possibly changes in other predicted outputs and classification performance. The boundary value for x for which p(x) = 0.5 and f(x)=0 is higher now - It's above 3. In this case, all our predictions are true, as shown by the accuracy, confusion matrix and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf670f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd9c4e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 0],\n",
       "       [0, 6]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75bb4031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, model.predict(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acf20a8",
   "metadata": {},
   "source": [
    "### Logistic Regression in Python with Scikit-Learn, Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36e6cbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 : Import packages, functions, classes\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "944f634d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2 : Get data\n",
    "\n",
    "x = np.arange(10).reshape(-1, 1)\n",
    "y = np.array([0, 1, 0, 0, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "len(x), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb551fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 : Create a model and train it\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', C=10.0, random_state=0).fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ecc1c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 : Evaluate the model\n",
    "\n",
    "p_pred = model.predict_proba(x)\n",
    "y_pred = model.predict(x)\n",
    "score = model.score(x,y)\n",
    "conf_m = confusion_matrix(y, y_pred)\n",
    "report = classification_report(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a378cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.51632619])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d430a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.703457]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c93edbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81999686, 0.18000314],\n",
       "       [0.69272057, 0.30727943],\n",
       "       [0.52732579, 0.47267421],\n",
       "       [0.35570732, 0.64429268],\n",
       "       [0.21458576, 0.78541424],\n",
       "       [0.11910229, 0.88089771],\n",
       "       [0.06271329, 0.93728671],\n",
       "       [0.03205032, 0.96794968],\n",
       "       [0.0161218 , 0.9838782 ],\n",
       "       [0.00804372, 0.99195628]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8626d1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f877ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7caff34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1],\n",
       "       [1, 6]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c70b31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         3\n",
      "           1       0.86      0.86      0.86         7\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.76      0.76      0.76        10\n",
      "weighted avg       0.80      0.80      0.80        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734c6d99",
   "metadata": {},
   "source": [
    "### Logistic Regression in Python with StatsModels, Example 3\n",
    "\n",
    "We can also implement logistic regression with the StatsModels package. We want to do this when we need more statistical details about models and results. The procedure is similar to scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c8bc617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 : Import packages\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5760b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 : Get data\n",
    "\n",
    "x = np.arange(10).reshape(-1, 1)\n",
    "y = np.array([0, 1, 0, 0, 1, 1, 1, 1, 1, 1])\n",
    "x = sm.add_constant(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f10f5c2",
   "metadata": {},
   "source": [
    "**.add_constant() takes the array x as the argument and returns a new array with the additional column of 1's**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "caf01e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 2.],\n",
       "        [1., 3.],\n",
       "        [1., 4.],\n",
       "        [1., 5.],\n",
       "        [1., 6.],\n",
       "        [1., 7.],\n",
       "        [1., 8.],\n",
       "        [1., 9.]]),\n",
       " array([0, 1, 0, 0, 1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61087b6f",
   "metadata": {},
   "source": [
    "The **first column of x corresponds to the intercept b0**. The **second column contains the original value of x**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2e6dd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 : Create a model and train it\n",
    "\n",
    "# Our logistic regression model is going to be an instance of the class statsmodels.discrete.discrete_model.Logit\n",
    "\n",
    "# We create it like this:\n",
    "\n",
    "model = sm.Logit(y,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69978036",
   "metadata": {},
   "source": [
    "Now we've created our model we want to fit it with our data. We do this with **.fit()**, or **if we want to apply L1 regularisation, using .fit_regularized()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "25dcba57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.350471\n",
      "         Iterations 7\n"
     ]
    }
   ],
   "source": [
    "result = model.fit(method='newton')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a599484",
   "metadata": {},
   "source": [
    "The model is now ready, and the variable result holds useful data. We can **obtain the values of b0 and b1 with .params**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0de60d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.972805  ,  0.82240094])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea262154",
   "metadata": {},
   "source": [
    "The **first element of the obtained array** is the **intercept b0**, while the **second** is the **slop b1**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "846d379b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12208792, 0.24041529, 0.41872657, 0.62114189, 0.78864861,\n",
       "       0.89465521, 0.95080891, 0.97777369, 0.99011108, 0.99563083])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4 : Evaluate the model\n",
    "\n",
    "We can use result to obtain the probabilities of the predicted outputs being equal to one:\n",
    "\n",
    "result.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb098e47",
   "metadata": {},
   "source": [
    "These probabilities are calculated with **.predict()**. We can use their values to get the **actual predicted outputs**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7c6953ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(result.predict(x) >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f611aa",
   "metadata": {},
   "source": [
    "We can **obtain the confusion matrix with .pred_table()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5974779b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 1.],\n",
       "       [1., 6.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.pred_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d983147a",
   "metadata": {},
   "source": [
    "The predicted outputs are equal to our scikit-learn model for logistic regression. However this is coincidental, as the differing processes used to calculate the result will in general differ between different packages.\n",
    "\n",
    "The confusion matrices we obtained with StatsModels and scikit-learn differ in the types of their elements as well (floating point numbers vs integers).\n",
    "\n",
    "**.summary()* and **.summary()2** get output data that you might find useful in some circumstances:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "470dc217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    10</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>     8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 08 Dec 2022</td> <th>  Pseudo R-squ.:     </th>  <td>0.4263</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>14:11:41</td>     <th>  Log-Likelihood:    </th> <td> -3.5047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -6.1086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td>0.02248</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -1.9728</td> <td>    1.737</td> <td>   -1.136</td> <td> 0.256</td> <td>   -5.377</td> <td>    1.431</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8224</td> <td>    0.528</td> <td>    1.557</td> <td> 0.119</td> <td>   -0.213</td> <td>    1.858</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   10\n",
       "Model:                          Logit   Df Residuals:                        8\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Thu, 08 Dec 2022   Pseudo R-squ.:                  0.4263\n",
       "Time:                        14:11:41   Log-Likelihood:                -3.5047\n",
       "converged:                       True   LL-Null:                       -6.1086\n",
       "Covariance Type:            nonrobust   LLR p-value:                   0.02248\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -1.9728      1.737     -1.136      0.256      -5.377       1.431\n",
       "x1             0.8224      0.528      1.557      0.119      -0.213       1.858\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "08059edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>   <td>0.426</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>         <td>y</td>              <td>AIC:</td>         <td>11.0094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2022-12-08 14:12</td>       <td>BIC:</td>         <td>11.6146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>         <td>10</td>         <td>Log-Likelihood:</td>   <td>-3.5047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>1</td>            <td>LL-Null:</td>       <td>-6.1086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>            <td>8</td>          <td>LLR p-value:</td>    <td>0.022485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>        <td>1.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>7.0000</td>              <td></td>              <td></td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>     <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>-1.9728</td>  <td>1.7366</td>  <td>-1.1360</td> <td>0.2560</td> <td>-5.3765</td> <td>1.4309</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>0.8224</td>   <td>0.5281</td>  <td>1.5572</td>  <td>0.1194</td> <td>-0.2127</td> <td>1.8575</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                        Results: Logit\n",
       "===============================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.426   \n",
       "Dependent Variable: y                AIC:              11.0094 \n",
       "Date:               2022-12-08 14:12 BIC:              11.6146 \n",
       "No. Observations:   10               Log-Likelihood:   -3.5047 \n",
       "Df Model:           1                LL-Null:          -6.1086 \n",
       "Df Residuals:       8                LLR p-value:      0.022485\n",
       "Converged:          1.0000           Scale:            1.0000  \n",
       "No. Iterations:     7.0000                                     \n",
       "-----------------------------------------------------------------\n",
       "          Coef.    Std.Err.      z      P>|z|     [0.025   0.975]\n",
       "-----------------------------------------------------------------\n",
       "const    -1.9728     1.7366   -1.1360   0.2560   -5.3765   1.4309\n",
       "x1        0.8224     0.5281    1.5572   0.1194   -0.2127   1.8575\n",
       "===============================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb0f665",
   "metadata": {},
   "source": [
    "### Logistic Regression in Python : Handwriting Recognition\n",
    "\n",
    "**Now we will solve a Machine Learning problem with a full-blown dataset**. For this we'll be using the **digits dataset** from **scikit-learn** library. It is an **image-recognition problem** of a **dataset containing 1797 observations**, each of which is a handwritten digit. **Each image has 64px, and is 8px * 8px.**\n",
    "\n",
    "**The inputs (x) are vectors with 64 dimensions or values.** \n",
    "\n",
    "**Each input vector describes one image.**\n",
    "\n",
    "**Each of the 64 values represents a pixel of the image**.\n",
    "\n",
    "**The input values are the integers between 0 and 16, depending on the shade of gray for the corresponding pixel.**\n",
    "\n",
    "**The output (y) for each obvservation is an integer between 0 and 9, consistent with the digit on the image.**\n",
    "\n",
    "**There are ten classes in total, each corresponding to one image**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c10a70",
   "metadata": {},
   "source": [
    "#### # Step 1 : Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cb5d6523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fb654c",
   "metadata": {},
   "source": [
    "#### Step 2a : Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e70fcf6",
   "metadata": {},
   "source": [
    "We can grab the dataset directly from scikit-learn with load_digits(). It **returns a tuple of the inputs and outputs**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fa1dc534",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " array([0, 1, 2, ..., 8, 9, 8]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = load_digits(return_X_y=True)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa5b4a1",
   "metadata": {},
   "source": [
    "That's our data to work with.\n",
    "\n",
    "**x is a multi-dimensional array with 1797 rows and 64 columns, containing integers from 0 to 16.**\n",
    "\n",
    "**y is a one-dimensional array with 1797 integers between 0 and 9**.\n",
    "\n",
    "#### Step 2b: Split Data\n",
    "\n",
    "Now we split the dataset into **training** and **test** data. We use the training set to fit our model. Once our model has been trained, we use the test set to test it, and evaluate its performance. It's important not to use training data for testing and vice versa.\n",
    "\n",
    "One way to **split our data** is to apply **train_test_split()**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6990b0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1da97f",
   "metadata": {},
   "source": [
    "**train_test_split() takes x, y, test_size, which determines the size of the test set, and random_state to define the state of the pseudo-random number generator, as well as other optional arguments**.\n",
    "\n",
    "The function **returns a list with four arrays**:\n",
    "\n",
    "1. **x_train**\n",
    "2. **x_test**\n",
    "3. **y_train**\n",
    "4. **y_test**\n",
    "\n",
    "Once our data is split, we can forget about x_test and y_test until we define our model.\n",
    "\n",
    "#### Step 2c : Scale Data\n",
    "\n",
    "**Standardisation** is the **process of transforming data** in such a way that **the mean of each column becomes equal to zero, and the standard deviation [std] of each column is 1.** This way, we obtain the same scale for all columns. **Take the following steps to standardise our data**:\n",
    "\n",
    "1. **Calculate** the mean and standard deviation for each column\n",
    "2. **Subtract** the corresponding mean from each element\n",
    "3. **Divide** the obtained difference by the corresponding standard deviation\n",
    "\n",
    "**It's a good practice to standardize the input data that we use for logistic regression, although in many cases it's not necessary.** Standardization **might improve the performance of our algorithm**. It helps if we need to **compare and interpret weights**. It's **important when we apply penalization because the algorithm is actually penalizing against large values in the weights**.\n",
    "\n",
    "We can **standardize our inputs** by **creating an instance of StandardScaler** and **calling .fit_transform()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ceb1567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cc8116",
   "metadata": {},
   "source": [
    "**fit_transform() fits the instance of StandardScaler to the array passed as an argument, transforms this array, and returns the new, standardized array.** Now **x_train** is a **standardised input array**.\n",
    "\n",
    "#### Step 3 : Create a Model and Train it\n",
    "\n",
    "This step is very similar the our previous examples. The **only difference** is that we **use x_train and y_train subsets to fit the model**. Again, we **create an instance of LogisticRegression** and **call .fit()** on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "66a2931f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.05, multi_class='ovr', random_state=0,\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', C=0.05, multi_class='ovr', random_state=0)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcac5789",
   "metadata": {},
   "source": [
    "**When we're working on problems with more than two classes, we must specifiy the multi_class parameter of LogisticRegression. It determines how to solve the problem:**\n",
    "\n",
    "- **'ovr'** says to make the binary fit for each class\n",
    "- **'multinomial'** says to apply the multinomial loss fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7bbe2730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.73645761, -2.77774361, -2.74028598, -2.72221436, -2.70234208,\n",
       "       -2.7232237 , -2.79949725, -2.74590013, -2.63851341, -2.75679358])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "19a8a2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00, -2.27680531e-02, -1.05198103e-02,\n",
       "         1.49272422e-01, -8.08210879e-02, -2.49747653e-01,\n",
       "        -5.14325206e-02, -5.45056683e-03, -2.32032737e-03,\n",
       "        -1.25447504e-01,  3.24463204e-02,  1.02987845e-01,\n",
       "         3.08882350e-01,  3.10625812e-01, -4.08016176e-02,\n",
       "        -1.34743379e-02,  1.08159828e-02,  7.79920142e-02,\n",
       "        -2.55957154e-02, -7.22962220e-03, -1.66787374e-01,\n",
       "         3.37966750e-01,  5.94210751e-02, -2.43160281e-02,\n",
       "         1.77634770e-02,  1.80673248e-01,  9.67450831e-03,\n",
       "        -2.68433227e-01, -4.95389929e-01, -1.28902641e-01,\n",
       "         1.70026784e-01, -2.89743863e-03,  0.00000000e+00,\n",
       "         1.45614546e-01,  1.70908304e-01, -3.15761191e-01,\n",
       "        -3.69687449e-01, -1.86967353e-01,  1.56212150e-01,\n",
       "         0.00000000e+00, -1.93245767e-02, -1.05328652e-01,\n",
       "         3.66928484e-01, -3.37811635e-01, -3.43997894e-01,\n",
       "         8.04630692e-03,  9.36489204e-03,  2.45574216e-03,\n",
       "        -2.34168093e-02, -1.60434709e-01,  2.20981289e-01,\n",
       "         1.17459875e-01,  2.02655733e-01,  1.35809376e-01,\n",
       "        -1.86910239e-01,  4.09616004e-02,  1.69808573e-02,\n",
       "        -3.10310929e-02, -6.51346885e-02,  1.32153332e-01,\n",
       "        -1.15788966e-01, -1.26820221e-01, -3.75484009e-02,\n",
       "         2.54458006e-02],\n",
       "       [ 0.00000000e+00, -4.44373438e-02, -6.11414628e-02,\n",
       "         9.97966593e-02, -4.20579584e-01,  3.24458917e-01,\n",
       "        -4.84569783e-05, -1.32045005e-02, -3.82352054e-03,\n",
       "        -3.03381685e-01, -4.72052001e-01, -1.23239601e-01,\n",
       "         1.85790411e-01,  2.21597957e-01, -2.23807977e-01,\n",
       "        -1.42761875e-02, -2.40102643e-02,  6.41414645e-02,\n",
       "        -6.02862552e-02,  5.55215494e-01,  5.09404144e-01,\n",
       "        -8.65023657e-02,  3.57981304e-04, -3.14763431e-02,\n",
       "        -6.15770282e-02,  1.28021862e-01,  1.04191322e-01,\n",
       "         2.67769020e-01,  6.41407147e-02,  7.98658866e-02,\n",
       "        -1.09772721e-01,  7.72937641e-03,  0.00000000e+00,\n",
       "        -6.35655511e-02, -2.60456408e-02,  2.98098794e-02,\n",
       "         3.95464434e-02, -7.52058354e-02, -1.56986497e-01,\n",
       "         0.00000000e+00,  1.77667165e-02, -2.42570672e-01,\n",
       "        -1.40219819e-01,  3.98028146e-02,  1.50191914e-01,\n",
       "        -2.64530991e-01, -7.47097669e-02, -8.89255324e-02,\n",
       "         1.89202005e-02, -1.33602049e-01, -3.85033642e-02,\n",
       "         1.60033091e-01,  1.90811927e-01,  1.86798857e-02,\n",
       "        -1.91119909e-01,  8.66291511e-02, -2.80266525e-02,\n",
       "        -2.71256220e-02, -2.08990465e-01,  1.03736817e-01,\n",
       "         1.36401041e-01,  2.38142133e-01, -8.30975617e-02,\n",
       "         1.41071902e-01],\n",
       "       [ 0.00000000e+00, -1.14895102e-02,  6.55063688e-02,\n",
       "        -7.68086700e-02, -4.30224304e-02, -1.16551265e-01,\n",
       "        -1.14722587e-02, -1.47179987e-02, -2.01991540e-02,\n",
       "         1.84312311e-01,  1.40192454e-01, -4.93724631e-02,\n",
       "         1.66589755e-01, -2.02632502e-01, -7.29878884e-03,\n",
       "         1.62213850e-02, -8.36474558e-04,  4.12103826e-02,\n",
       "         8.16746353e-02, -2.40005967e-01,  8.00378170e-02,\n",
       "        -3.14566257e-02,  1.03485112e-01,  1.00569255e-01,\n",
       "         5.62380385e-03, -1.20559280e-01, -3.19854890e-01,\n",
       "        -5.54026921e-01,  9.41128408e-02,  9.17829698e-02,\n",
       "         1.04083314e-03,  9.33207282e-03,  0.00000000e+00,\n",
       "        -2.42306756e-02, -2.97216658e-01, -6.09841140e-02,\n",
       "        -7.73826711e-02, -1.86785934e-01, -2.14458767e-01,\n",
       "         0.00000000e+00, -3.96979020e-02,  8.82073738e-02,\n",
       "         1.69726943e-02,  4.88727227e-01, -2.96020813e-01,\n",
       "        -4.31386092e-01, -4.04634351e-01,  6.18158507e-02,\n",
       "        -2.47434359e-02,  1.93590919e-01,  3.67891375e-02,\n",
       "         2.79515331e-01,  3.97902075e-01,  3.24684320e-01,\n",
       "         1.87133795e-01,  1.29983556e-03,  8.48567298e-02,\n",
       "         5.25890088e-02,  1.25612390e-01, -4.26107083e-03,\n",
       "         5.12735614e-02,  2.67130048e-01,  3.85991506e-01,\n",
       "        -4.94859683e-02],\n",
       "       [ 0.00000000e+00,  4.55226633e-02, -1.17387769e-01,\n",
       "         1.23691417e-01,  3.01263861e-01,  9.22022302e-03,\n",
       "        -8.48382276e-02, -1.76766207e-02, -5.45065836e-02,\n",
       "         8.21433959e-02,  8.01532258e-02,  4.59387682e-02,\n",
       "        -1.09437952e-04,  1.96397972e-01,  2.15337498e-01,\n",
       "        -1.69518860e-02, -4.89683028e-03, -1.38080327e-01,\n",
       "        -5.49448076e-01, -2.69680821e-01,  3.43849063e-01,\n",
       "        -6.95095322e-02, -3.56837920e-04,  2.98738262e-02,\n",
       "         4.57663133e-02, -1.36206101e-01, -3.95911571e-01,\n",
       "        -9.35917743e-02,  9.93697268e-03, -4.81286693e-01,\n",
       "        -2.72462776e-01,  4.30380729e-02,  0.00000000e+00,\n",
       "         7.84795323e-02, -1.50195010e-01, -1.92638336e-01,\n",
       "         2.37762053e-01,  1.72072900e-01, -1.68972963e-01,\n",
       "         0.00000000e+00,  4.99726341e-02,  8.43570496e-02,\n",
       "        -2.04806604e-01, -5.48236321e-01, -1.52546679e-04,\n",
       "         4.07796961e-01,  3.98956086e-01, -1.78309684e-02,\n",
       "        -1.08716146e-02, -3.29500488e-02, -3.30977891e-02,\n",
       "        -1.53934404e-01,  7.86975863e-02,  5.42426018e-03,\n",
       "         1.91754702e-01, -8.51289781e-02,  2.45045316e-02,\n",
       "        -1.53176298e-03,  1.00115881e-01,  1.05195111e-01,\n",
       "         1.56971718e-01,  1.31768063e-03, -1.40363400e-01,\n",
       "        -1.12743289e-01],\n",
       "       [ 0.00000000e+00,  1.07076861e-02, -3.69131921e-02,\n",
       "        -3.68237579e-01, -5.19344709e-02, -3.87139474e-01,\n",
       "        -2.12789574e-01,  1.01083535e-02,  7.77393705e-03,\n",
       "         1.72062117e-01, -1.86095665e-01, -1.30327567e-01,\n",
       "        -3.19146172e-01, -3.49394508e-01, -1.27575430e-01,\n",
       "        -4.41857450e-02,  6.05376449e-03, -1.46997118e-02,\n",
       "         1.01490319e-01,  1.37854962e-01, -1.82812922e-02,\n",
       "         4.96470486e-02,  2.22717067e-02,  1.22106072e-01,\n",
       "         1.03880751e-01,  2.78577063e-02,  1.72682358e-01,\n",
       "        -1.21058445e-01,  1.05619306e-01,  1.15547914e-01,\n",
       "         3.05042154e-01,  1.54499855e-01,  0.00000000e+00,\n",
       "         3.52048951e-01, -3.61737291e-02, -6.88254304e-02,\n",
       "         1.82143814e-01,  1.89576943e-01,  1.94975806e-01,\n",
       "         0.00000000e+00,  1.64382832e-01,  3.46939795e-01,\n",
       "        -1.27103621e-01,  3.74784767e-01,  2.95855032e-01,\n",
       "         1.05003469e-01, -8.79309307e-02, -1.60032206e-02,\n",
       "         6.36893246e-02,  2.13557224e-01, -2.44063512e-01,\n",
       "        -1.42962410e-01,  8.86628921e-02, -2.88615230e-01,\n",
       "        -1.51709570e-01,  9.12698605e-03, -6.05307275e-02,\n",
       "         2.25727179e-02,  2.61642731e-02, -9.52738136e-02,\n",
       "         1.27269322e-01, -2.69259908e-01, -3.48271611e-02,\n",
       "        -1.46280102e-02],\n",
       "       [ 0.00000000e+00,  2.89637490e-02,  3.71316463e-01,\n",
       "        -1.48659977e-01,  1.85849270e-01,  4.06789418e-01,\n",
       "         2.87649616e-01, -1.00039925e-01,  1.87358454e-02,\n",
       "        -2.78480845e-02,  1.44030202e-01,  1.10488117e-01,\n",
       "         1.01613305e-01, -2.10293679e-01, -1.35508880e-01,\n",
       "        -3.46951009e-02, -3.02347604e-02,  9.39194609e-02,\n",
       "         1.82589938e-01, -2.15179169e-02, -5.83320612e-01,\n",
       "        -6.33148632e-01, -3.79687183e-01,  3.95529147e-02,\n",
       "        -7.20265650e-02,  2.29548477e-01,  3.28995091e-01,\n",
       "         1.53594846e-01,  1.47700689e-01, -1.37988742e-02,\n",
       "        -2.29267908e-01,  1.41292352e-02,  0.00000000e+00,\n",
       "        -7.14467222e-02,  1.40603070e-01, -1.36862135e-01,\n",
       "        -1.00994341e-01, -6.97925611e-03,  2.01705093e-02,\n",
       "         0.00000000e+00,  6.84927002e-03, -1.45473970e-01,\n",
       "        -3.42310796e-01, -2.38555007e-01, -1.80026869e-02,\n",
       "         2.83724964e-02,  2.78631409e-02, -1.57210862e-02,\n",
       "         2.59390766e-02,  1.78191880e-02, -7.51325884e-02,\n",
       "        -6.62250197e-02,  5.48000985e-02, -6.27341888e-02,\n",
       "        -1.85620786e-01,  4.73468754e-02,  5.99367557e-04,\n",
       "         7.90365464e-02,  2.72969464e-01,  1.71316701e-01,\n",
       "        -1.10872366e-01, -1.46722591e-01, -9.13261157e-02,\n",
       "        -9.65356306e-02],\n",
       "       [ 0.00000000e+00, -1.22761568e-02, -2.14068940e-01,\n",
       "         5.87318015e-02, -4.24323019e-02, -3.40820692e-02,\n",
       "         3.08703433e-02, -2.11367243e-02,  7.92597809e-03,\n",
       "        -1.28306281e-01, -1.29166228e-01, -1.83532851e-03,\n",
       "        -2.10426008e-01, -1.79404471e-01,  1.17460568e-01,\n",
       "         1.32380911e-02,  5.71512390e-03, -1.84888778e-01,\n",
       "         1.02903494e-01, -4.47247737e-02, -2.30172948e-01,\n",
       "        -4.19381849e-01, -7.56003023e-02,  8.26909907e-03,\n",
       "         4.36763592e-03, -9.81837623e-02,  1.05082912e-01,\n",
       "        -2.19926549e-02, -2.12235600e-01, -2.10646336e-01,\n",
       "        -2.89755845e-01,  5.65963963e-03,  0.00000000e+00,\n",
       "         2.37823583e-03,  3.00682257e-01,  1.61864368e-01,\n",
       "         7.34650812e-02,  1.84439009e-01, -1.50938167e-01,\n",
       "         0.00000000e+00, -1.20440324e-02, -2.15433074e-01,\n",
       "         2.99034323e-01,  9.29099120e-02,  4.44766936e-02,\n",
       "         1.09398101e-01,  3.04426869e-01,  2.22254744e-01,\n",
       "         1.72771133e-02, -1.20491796e-01,  1.67439996e-01,\n",
       "         2.95282939e-01, -2.84515757e-01,  1.81893988e-01,\n",
       "         3.10796058e-01, -1.45650894e-01,  2.36626266e-02,\n",
       "        -1.59159800e-02, -8.59444399e-02, -6.81198461e-02,\n",
       "        -4.24768128e-02,  2.43267308e-01, -2.26465844e-02,\n",
       "        -8.41442311e-02],\n",
       "       [ 0.00000000e+00,  8.77353842e-04, -3.16396412e-02,\n",
       "         1.49190781e-01,  1.43412368e-01,  1.77607436e-01,\n",
       "         2.07416913e-01,  2.28849160e-01,  1.09924870e-02,\n",
       "        -4.20225686e-02,  1.98794155e-01,  8.75998628e-02,\n",
       "         2.99241298e-01,  6.09922859e-02,  2.00021581e-02,\n",
       "         1.32414706e-01,  8.29753186e-03, -6.32674050e-02,\n",
       "        -2.76639759e-01, -2.57440813e-01, -7.70608516e-02,\n",
       "         7.95899130e-03, -1.36145942e-02, -7.73775842e-02,\n",
       "         9.78655708e-03, -2.70316956e-01, -2.24676327e-01,\n",
       "        -2.22144874e-01, -3.15211046e-02,  1.88866641e-01,\n",
       "         2.30150627e-01, -1.76288862e-01,  0.00000000e+00,\n",
       "        -1.23903709e-01,  1.77087562e-01,  1.48722582e-01,\n",
       "         1.94550254e-01,  2.61870352e-01,  3.01871826e-01,\n",
       "         0.00000000e+00,  8.51152582e-04, -8.28633583e-02,\n",
       "         6.57379612e-02,  1.45917423e-01,  1.11365827e-01,\n",
       "        -5.64304585e-02, -7.86052334e-02, -3.83146779e-02,\n",
       "         6.67713138e-02, -4.48210714e-02, -6.78538809e-02,\n",
       "         1.64584580e-01, -4.95463968e-01, -2.99517820e-01,\n",
       "        -5.60217037e-02,  2.72190348e-02, -5.81639856e-03,\n",
       "        -1.21498887e-01, -5.62281056e-03, -8.87913964e-02,\n",
       "        -5.06987997e-01, -1.60547390e-01, -7.28566287e-02,\n",
       "         6.90251877e-02],\n",
       "       [ 0.00000000e+00, -6.03331783e-02, -1.71319639e-02,\n",
       "        -2.17055547e-01,  7.95354252e-02, -6.13072799e-02,\n",
       "        -3.12748320e-01, -2.67207476e-02,  3.95209074e-02,\n",
       "        -5.59051577e-02,  2.95629271e-01, -3.48354139e-02,\n",
       "        -2.57038864e-01,  2.94408387e-01,  1.70016383e-01,\n",
       "         1.10008478e-02,  7.53230649e-02,  1.20514748e-01,\n",
       "         3.84779682e-01,  2.90221252e-02, -7.82747805e-02,\n",
       "         3.05912396e-01,  1.39138890e-01, -5.08984622e-02,\n",
       "        -5.00298133e-03, -1.04087813e-01, -4.94151636e-02,\n",
       "         4.27728779e-01,  6.88103780e-02,  6.22544547e-02,\n",
       "        -1.66883527e-01, -1.65624112e-02,  0.00000000e+00,\n",
       "        -2.61674354e-01, -1.78190175e-01,  4.74130050e-01,\n",
       "         2.37619473e-01, -3.56920872e-01, -3.03090780e-01,\n",
       "         0.00000000e+00, -1.36236514e-03,  8.69898343e-02,\n",
       "         4.80990644e-01,  1.06859366e-01,  1.44440319e-01,\n",
       "         1.95931209e-01, -1.24730757e-01,  1.60725965e-02,\n",
       "         2.23557642e-02, -1.42881110e-02,  2.86593552e-01,\n",
       "        -3.25431018e-01, -2.77093323e-01,  1.86946749e-01,\n",
       "        -5.65460739e-02, -2.65018586e-02, -3.81154226e-02,\n",
       "        -1.25717685e-02, -2.46488030e-01,  4.69456847e-02,\n",
       "         1.15303898e-01, -2.35240525e-01, -1.96978585e-02,\n",
       "        -8.56106673e-03],\n",
       "       [ 0.00000000e+00, -6.52262121e-02, -5.75787099e-02,\n",
       "         1.38284753e-01, -6.25506645e-02, -2.85441254e-01,\n",
       "        -3.17168671e-02, -6.28906272e-02, -1.09013693e-02,\n",
       "         3.18990717e-02,  1.29664845e-01, -3.88601666e-03,\n",
       "        -4.02446071e-02,  1.80530751e-02,  7.37060714e-02,\n",
       "        -8.99211829e-03, -2.47437582e-03,  1.01770320e-01,\n",
       "         3.08509685e-01,  5.26606300e-02,  7.44487397e-02,\n",
       "         5.70979753e-01,  1.42443364e-01, -1.20890540e-01,\n",
       "         7.41060843e-03, -1.92562202e-01,  3.01215794e-01,\n",
       "         3.40857680e-01,  1.96820731e-01,  3.99260761e-01,\n",
       "         9.11084287e-02, -5.48250014e-02,  0.00000000e+00,\n",
       "        -3.15236699e-01, -1.44875710e-01,  2.17123360e-01,\n",
       "        -4.90272798e-01,  3.16645301e-02,  1.11484729e-01,\n",
       "         0.00000000e+00,  4.75093867e-02,  6.96854622e-02,\n",
       "        -5.52575642e-01, -3.44452909e-01, -2.21904834e-01,\n",
       "        -8.42745499e-02, -3.54664935e-02, -1.89825187e-02,\n",
       "         1.07298191e-02,  1.25174136e-01, -1.88266908e-01,\n",
       "        -1.62989165e-01, -1.30090391e-01, -2.98002831e-01,\n",
       "         1.14409458e-01,  5.41314593e-02, -1.07742596e-03,\n",
       "        -4.64915158e-02, -5.58035842e-02, -1.64061807e-01,\n",
       "         2.00293988e-01, -1.57753396e-02,  5.66475795e-02,\n",
       "        -1.04948628e-01]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aa4cf5",
   "metadata": {},
   "source": [
    "#### Step 4 : Evaluate the Model\n",
    "\n",
    "We should **evaluate our model** similar to how we did in the previous examples, **except we'll mostly use x_test and y_test, the subsets not applied for training**. \n",
    "\n",
    "**If we've decided to standardise x_train, then the obtained model relies on the scaled data, so x_test should be scaled as well with the same instance of StandardScaler.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d79ed211",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567e74a1",
   "metadata": {},
   "source": [
    "That's how we get a **new, properly scaled x_test**. In this case we use **.transform()**, which only transforms the argument without fitting the scaler.\n",
    "\n",
    "Let's **obtain the predicted outputs** with **.predict()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b41ce4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b453bd",
   "metadata": {},
   "source": [
    "And check the **accuracy** with **.score()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2e5d4cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.964509394572025"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "99b64b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9416666666666667"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c20c54",
   "metadata": {},
   "source": [
    "As we can see, **we have two different values for the accuracy** - **One for the training set, and one for the test set**It might be a **good idea to compare the two**, as a situation where the **training set accuracy is much higher may indicate overfitting**. The **test set accuracy is more relevant for evaluating the performance on unseen data since it's not biased**.\n",
    "\n",
    "We can get the confusion matrix with **confusion_matrix()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b90003af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 32,  0,  0,  0,  0,  1,  0,  1,  1],\n",
       "       [ 1,  1, 33,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  1, 28,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 29,  0,  0,  1,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 39,  0,  0,  0,  1],\n",
       "       [ 0,  1,  0,  0,  0,  0, 43,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 39,  0,  0],\n",
       "       [ 0,  2,  1,  2,  0,  0,  0,  1, 33,  0],\n",
       "       [ 0,  0,  0,  1,  0,  1,  0,  2,  1, 36]], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b887fd36",
   "metadata": {},
   "source": [
    "Let's **visualise** it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4e385be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.set_xlabel('Predicted outputs', fontsize='small', color='black')\n",
    "ax.set_ylabel('Actual outputs', fontsize='small', color='black')\n",
    "ax.xaxis.set(ticks=range(10))\n",
    "ax.yaxis.set(ticks=range(10))\n",
    "ax.set_ylim(9.5, -0.5)\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd53c932",
   "metadata": {},
   "source": [
    "This is a **heatmap** that illustrates the confusion matrix with **numbers and colours**. We can see that the **shades of purple represent small numbers [like 0, 1, 2 etc] and green or yellow represent large numbers [27 or above].**\n",
    "\n",
    "The numbers on the **main diagonal** show the **number of correct predictions from the test set**. Other numbers correspond to incorrect predictions.\n",
    "\n",
    "Finally, we can **get the report on classification as a string or a dict with classification_report()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "68be3d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        27\n",
      "           1       0.89      0.91      0.90        35\n",
      "           2       0.94      0.92      0.93        36\n",
      "           3       0.88      0.97      0.92        29\n",
      "           4       1.00      0.97      0.98        30\n",
      "           5       0.97      0.97      0.97        40\n",
      "           6       0.98      0.98      0.98        44\n",
      "           7       0.91      1.00      0.95        39\n",
      "           8       0.94      0.85      0.89        39\n",
      "           9       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.94       360\n",
      "   macro avg       0.94      0.94      0.94       360\n",
      "weighted avg       0.94      0.94      0.94       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d3e131",
   "metadata": {},
   "source": [
    "### Beyond Logistic Regression in Python\n",
    "\n",
    "Logistic regression is a fundamental classification technique. It's a relatively uncomplicated linear classifier. Despite its simplicity and popularity, there are cases where logistic regression doesn't work well. In such circumstances, you can use other classification techniques:\n",
    "\n",
    "- k-Nearest Neighbour\n",
    "- Naive Bayes classifiers\n",
    "- Support Vector Machines\n",
    "- Decision Trees\n",
    "- Random Forests\n",
    "- Neural Networks\n",
    "\n",
    "Scikit-learn implements all of the above-mentioned techniques, with the exception of neural networks. **For all of these techniques, scikit-learn offers suitable classes with methods like .fit(), .predict_proba(), .predict(), .score()**, etc. **You can combine them with tran_test_split(), confusion_matrix(), classification_report()** and others."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
