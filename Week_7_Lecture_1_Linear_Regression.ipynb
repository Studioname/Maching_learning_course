{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1837aece",
   "metadata": {},
   "source": [
    "## ML Terminology\n",
    "\n",
    "### Dependent Variables:\n",
    "\n",
    "Also known as outcome variables.\n",
    "\n",
    "Assumed to be linked or predictable from other variables.\n",
    "\n",
    "Also known as target or label variable.\n",
    "\n",
    "Also known as y variables.\n",
    "\n",
    "### Independent Variables:\n",
    "\n",
    "Also known as predictor variables.\n",
    "\n",
    "They have inherent variation.\n",
    "\n",
    "There should be no relationships between independent variables.\n",
    "\n",
    "Also referred to as features and dimensions.\n",
    "\n",
    "We use them to predict variance in the dependent variable.\n",
    "\n",
    "e.g sex, age, education level when we're trying to predict test scores\n",
    "\n",
    "Also known as x variables.\n",
    "\n",
    "### Supervised Learning\n",
    "\n",
    "Has both a dependent variable and an independent variable\n",
    "\n",
    "Say we want to predict the value one variable will take based on measurements from other variables, like shoe size from height\n",
    "\n",
    "### Unsupervised Learning\n",
    "\n",
    "Has only features\n",
    "\n",
    "We don't have an outcome or dependent variable (y) or we leave it out\n",
    "\n",
    "Is used to determine the variables that account for the most variation of the data, or group data based on similarity of features Y\n",
    "\n",
    "### Models\n",
    "\n",
    "In ML we create a model to define the relationship between the independent variables (x) and the dependent variables (y)\n",
    "\n",
    "We train the model so that it can learn the relationship between x and y\n",
    "\n",
    "We can then use it to make predictions on a new dataset where we don't know y\n",
    "\n",
    "### Linear Regression\n",
    "\n",
    "Linear regression is used when the Y variable is continuous; it predicts a continuous Y value\n",
    "\n",
    "Linear regression is associated with linearity\n",
    "\n",
    "### Logistic Regression\n",
    "\n",
    "Logistic regression is used when the Y variable is discrete [true or false, 0 or 1 etc]\n",
    "\n",
    "Logistic regression predicts a discrete Y value [ie a non linear value, either 0 or 1, true or false etc]\n",
    "\n",
    "### Variance\n",
    "\n",
    "We can think of variance as an estimate of how spread out the data is.\n",
    "\n",
    "How far is the data from the mean?\n",
    "\n",
    "Is there a relationship between the variance of the dependent variable and the independent variable?\n",
    "\n",
    "### Normal Distribution\n",
    "\n",
    "A normal distribution has a bell shaped curve\n",
    "\n",
    "It is symmetrical around the mean\n",
    "\n",
    "No bias left or right\n",
    "\n",
    "### Standard Deviation and Variance\n",
    "\n",
    "Variance is the average of the squared differences of measured data from the mean\n",
    "\n",
    "The standard deviation is the average difference of measured data from the mean [the square root of the variance]\n",
    "\n",
    "### Data bias\n",
    "\n",
    "Training dataset reinforces inherent bias in historical data\n",
    "\n",
    "For instance, using google translate will translate 'He is cooking' to 'She is cooking', or 'She is the president' to 'He is the president' when translating from English to Turkish.\n",
    "\n",
    "Non-random sampling - The training dataset is not represenative of the population it is trying to model.\n",
    "\n",
    "### Variables in Linear Regression\n",
    "\n",
    "The classic regression case involves one dependent variable and one independent variable\n",
    "\n",
    "We're trying to explain or predict the variation in Y based on the variation in X\n",
    "\n",
    "When we have multiple X variables it is called Multiple Linear Regression\n",
    "\n",
    "### Simple Linear Regression\n",
    "\n",
    "If i give you a vector of X values and a vector of corresponding Y values\n",
    "\n",
    "Then ask you to estimate the Y value for a new X\n",
    "\n",
    "What do you do?\n",
    "\n",
    "You could plot the data and decide whether a linear relationship between X and Y looks likely\n",
    "\n",
    "We can then ask what line provides a best guess for Y based on X, or a 'line of best fit'\n",
    "\n",
    "We need two things for a line: the slope/gradient (m) and intercept (c). Thus y = mx + c\n",
    "\n",
    "We could make a hand drawn guess at a line that fits the data. But how can we be systematic about it?\n",
    "\n",
    "y = dependent var\n",
    "\n",
    "m = coefficient, rate of change/slope/gradient\n",
    "\n",
    "x = independent var\n",
    "\n",
    "c = where the line crosses the y-axis [also known as the y-intercept]\n",
    "\n",
    "y = mx + c\n",
    "\n",
    "### Equation of a straight line in ML\n",
    "\n",
    "y = β₁x + β₀\n",
    "\n",
    "y = Dependent variable\n",
    "\n",
    "β₁ = Predictor coefficient/variable\n",
    "\n",
    "x = Independent variable\n",
    "\n",
    "β₀ = Intercept coefficient/variable\n",
    "\n",
    "\n",
    "### How to get the best fit line in ML\n",
    "\n",
    "Method of Least Squares\n",
    "\n",
    "For any given line y = β₁x + β₀ we can measure the vertical differences between the actual Y values and those predicted by our hypothesized line\n",
    "\n",
    "The vertical differences are our 'error', also called residuals for our regression line\n",
    "\n",
    "So true y values are e away from the regression line\n",
    "\n",
    "y = β₁x + β₀ + e\n",
    "\n",
    "e = random error\n",
    "\n",
    "We can use this 'error' term, e, as a quantitative measure of how good a fit a regression line is\n",
    "\n",
    "Some of our errors/residuals will be positive and some negative\n",
    "\n",
    "If we sum all of our e values from all of our points the positives will cancel out the negatives giving us a false measure of error\n",
    "\n",
    "How do we overcome this?\n",
    "\n",
    "We remove the sign of the error by squaring the differences and then summing them\n",
    "\n",
    "The regression line with the lowest sum of its squared errors/residuals is the optimal/best fit (closer to zero the better)\n",
    "\n",
    "### Assumptions of simple linear regression\n",
    "\n",
    "There is a linear relationship between the independent and dependent variable\n",
    "\n",
    "The error/residuals have a normal distirbution\n",
    "\n",
    "There is a constant variance of the errors/residuals vs the predicted independent variable (for best precision)\n",
    "\n",
    "If these assumptions are not met, then our model may not be very accurate, or worse, seriously wrong\n",
    "\n",
    "### Multiple Linear Regression\n",
    "\n",
    "When we have many X variables, the weights of nonpredictive features/variables in the model are set to zero [ie removed from the equation]\n",
    "\n",
    "We now have an equation describing the best fit line\n",
    "\n",
    "y = β₀ + β₂x₂ - β₅x₅ - β₇x₇ + β₈x₈\n",
    "\n",
    "Weights β₁, β₃, β₄, β₆ have been set to zero\n",
    "\n",
    "We can use this equation to predict the value of y on a new dataset where we do not know y, e.g sales based on marketing strategy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
